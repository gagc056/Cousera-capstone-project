{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Download the data"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\nconcrete_data.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "concrete_data.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Let's check the dataset for any missing values.\nconcrete_data.describe()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "concrete_data.isnull().sum()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Split data into predictors and target\nThe target variable in this problem is the concrete sample strength. Therefore, our predictors will be all the other columns."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "concrete_data_columns = concrete_data.columns\n\npredictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\ntarget = concrete_data['Strength'] # Strength column"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Let's do a quick sanity check of the predictors and the target dataframes.\npredictors.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "target.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Let's save the number of predictors to _n_cols_ since we will need this number when building our network.\nn_cols = predictors.shape[1] # number of predictors\nn_cols"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Build a Neural Network\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def regression_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n    model.add(Dense(1))\n    \n    # compile model\n    model.compile(optimizer='Adam', loss='mean_squared_error')\n    return model"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=4)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# build the model\nmodel = regression_model()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Train and Test the Network"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# build the model\nmodel.fit( X_test, y_test,epochs=50, verbose=2)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "loss = model.evaluate(X_test, y_test)\ny_hat = model.predict(X_test)\nloss"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a list of mean squared errors and  the standard deviation of the mean squared errors\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "total_mean_squared_errors = 50\nmean_squared_errors = []\nfor i in range(0,total_mean_squared_errors):\n    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=4)\n    model.fit(X_train, y_train, epochs=50, verbose=0)\n    MSE = model.evaluate(X_test, y_test, verbose=0)\n    print(\"MSE \"+str(i+1)+\": \"+str(MSE))\n    y_hat = model.predict(X_test)\n    errors = mean_squared_error(y_test, y_hat)\n    mean_squared_errors.append(errors)\n    \nmean = np.mean(np.array(mean_squared_errors))\nSTD = np.std(mean_squared_errors)\nprint(\"Mean: \",str(mean), \"Standard Deviation:\",str(STD))\n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}